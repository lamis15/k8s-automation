---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  - networking.k8s.io
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs:
  - /metrics
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager.monitoring.svc.cluster.local:9093

    rule_files:
      - /etc/prometheus/alert-rules.yml

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/$1/proxy/metrics

      - job_name: 'kubernetes-cadvisor'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.monitoring.svc.cluster.local:8080']

      - job_name: 'node-exporter'
        static_configs:
{% for host in groups['k8s_cluster'] %}
          - targets: ['{{ hostvars[host]['ansible_host'] }}:9100']
            labels:
              instance: '{{ hostvars[host]['inventory_hostname'] }}'
{% endfor %}

  alert-rules.yml: |
    groups:
      - name: node-alerts
        rules:
          - alert: HighCPUUsage
            expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage on {% raw %}{{ $labels.instance }}{% endraw %}"
              description: "CPU usage is above 80% for 5 minutes (current: {% raw %}{{ $value }}{% endraw %}%)"

          - alert: HighMemoryUsage
            expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 85
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "High memory usage on {% raw %}{{ $labels.instance }}{% endraw %}"
              description: "Memory usage is above 85% for 5 minutes (current: {% raw %}{{ $value }}{% endraw %}%)"

          - alert: HighDiskUsage
            expr: (1 - node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 > 80
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "High disk usage on {% raw %}{{ $labels.instance }}{% endraw %}"
              description: "Disk usage is above 80% (current: {% raw %}{{ $value }}{% endraw %}%)"

          - alert: NodeDown
            expr: up{job="node-exporter"} == 0
            for: 30s
            labels:
              severity: critical
            annotations:
              summary: "Node {% raw %}{{ $labels.instance }}{% endraw %} is down"
              description: "Node exporter is not reachable for 1 minute"

      - name: kubernetes-alerts
        rules:
          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 0
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "Pod {% raw %}{{ $labels.namespace }}/{{ $labels.pod }}{% endraw %} is crash looping"

          - alert: PodNotReady
            expr: kube_pod_status_phase{phase=~"Pending|Unknown"} > 0
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "Pod {% raw %}{{ $labels.namespace }}/{{ $labels.pod }}{% endraw %} not ready"

          - alert: DeploymentReplicasMismatch
            expr: kube_deployment_spec_replicas != kube_deployment_status_ready_replicas
            for: 30s
            labels:
              severity: warning
            annotations:
              summary: "Deployment {% raw %}{{ $labels.namespace }}/{{ $labels.deployment }}{% endraw %} replicas mismatch"
